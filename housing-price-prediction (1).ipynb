{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10211,"databundleVersionId":111096,"sourceType":"competition"}],"dockerImageVersionId":30804,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom xgboost import XGBRegressor\nfrom sklearn.model_selection import RandomizedSearchCV\n\n# Read the data\niowa_file_path = '/kaggle/input/home-data-for-ml-course/train.csv'\nhome_data = pd.read_csv(iowa_file_path)\n\n# Remove rows with missing target\nhome_data.dropna(axis=0, subset=['SalePrice'], inplace=True) \n\n# Set the prediction target and separate it from the rest of the data\ny = home_data.SalePrice\nhome_data.drop(['SalePrice'], axis=1, inplace=True) \n\n# Set the prediction data to X_full\nX_full = home_data\ndisplay(X_full.columns)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T22:15:36.809759Z","iopub.execute_input":"2025-02-05T22:15:36.810391Z","iopub.status.idle":"2025-02-05T22:15:38.097906Z","shell.execute_reply.started":"2025-02-05T22:15:36.810305Z","shell.execute_reply":"2025-02-05T22:15:38.096826Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Index(['Id', 'MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street',\n       'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig',\n       'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType',\n       'HouseStyle', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd',\n       'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType',\n       'MasVnrArea', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual',\n       'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1',\n       'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating',\n       'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF',\n       'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',\n       'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType',\n       'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual',\n       'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF',\n       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'PoolQC',\n       'Fence', 'MiscFeature', 'MiscVal', 'MoSold', 'YrSold', 'SaleType',\n       'SaleCondition'],\n      dtype='object')"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-05T22:15:36.377892Z","iopub.execute_input":"2025-02-05T22:15:36.378187Z","iopub.status.idle":"2025-02-05T22:15:36.807395Z","shell.execute_reply.started":"2025-02-05T22:15:36.378155Z","shell.execute_reply":"2025-02-05T22:15:36.806250Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/home-data-for-ml-course/sample_submission.csv\n/kaggle/input/home-data-for-ml-course/sample_submission.csv.gz\n/kaggle/input/home-data-for-ml-course/train.csv.gz\n/kaggle/input/home-data-for-ml-course/data_description.txt\n/kaggle/input/home-data-for-ml-course/test.csv.gz\n/kaggle/input/home-data-for-ml-course/train.csv\n/kaggle/input/home-data-for-ml-course/test.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# Trying Descision Tree Regressor","metadata":{}},{"cell_type":"code","source":"# List of chosen features\nfeatures = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']\n\n# Select data and display it\nX1 = home_data[features]\ndisplay(X1.head())\n\n# Split data into validation and training data\nX1_train, X1_valid, y1_train, y1_valid = train_test_split(X1, y, random_state = 1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T22:15:38.099426Z","iopub.execute_input":"2025-02-05T22:15:38.099881Z","iopub.status.idle":"2025-02-05T22:15:38.120521Z","shell.execute_reply.started":"2025-02-05T22:15:38.099824Z","shell.execute_reply":"2025-02-05T22:15:38.119395Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"   LotArea  YearBuilt  1stFlrSF  2ndFlrSF  FullBath  BedroomAbvGr  \\\n0     8450       2003       856       854         2             3   \n1     9600       1976      1262         0         2             3   \n2    11250       2001       920       866         2             3   \n3     9550       1915       961       756         1             3   \n4    14260       2000      1145      1053         2             4   \n\n   TotRmsAbvGrd  \n0             8  \n1             6  \n2             6  \n3             7  \n4             9  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>LotArea</th>\n      <th>YearBuilt</th>\n      <th>1stFlrSF</th>\n      <th>2ndFlrSF</th>\n      <th>FullBath</th>\n      <th>BedroomAbvGr</th>\n      <th>TotRmsAbvGrd</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>8450</td>\n      <td>2003</td>\n      <td>856</td>\n      <td>854</td>\n      <td>2</td>\n      <td>3</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>9600</td>\n      <td>1976</td>\n      <td>1262</td>\n      <td>0</td>\n      <td>2</td>\n      <td>3</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>11250</td>\n      <td>2001</td>\n      <td>920</td>\n      <td>866</td>\n      <td>2</td>\n      <td>3</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9550</td>\n      <td>1915</td>\n      <td>961</td>\n      <td>756</td>\n      <td>1</td>\n      <td>3</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>14260</td>\n      <td>2000</td>\n      <td>1145</td>\n      <td>1053</td>\n      <td>2</td>\n      <td>4</td>\n      <td>9</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"# Defining Decision Tree\ndt_model = DecisionTreeRegressor(random_state = 0)\n\n# Fitting model\ndt_model.fit(X1_train, y1_train)\n\n# Get Predictions\ndt_predictions = dt_model.predict(X1_valid)\n\n# Print Mean Absolute Error\ndt_val_mae = mean_absolute_error(dt_predictions, y1_valid)\nprint(\"Validation MAE for Decision Tree Regressor: \", dt_val_mae)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T22:15:38.122207Z","iopub.execute_input":"2025-02-05T22:15:38.122685Z","iopub.status.idle":"2025-02-05T22:15:38.143731Z","shell.execute_reply.started":"2025-02-05T22:15:38.122637Z","shell.execute_reply":"2025-02-05T22:15:38.142403Z"}},"outputs":[{"name":"stdout","text":"Validation MAE for Decision Tree Regressor:  29478.638356164385\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"**Finding the optimal number of leaf nodes to improve model accuracy**","metadata":{}},{"cell_type":"code","source":"# Function that will input the maximum number of leaf nodes and return the MAE\ndef get_mae(max_leaf_nodes, X_train, X_valid, y_train, y_valid):\n    model = DecisionTreeRegressor(max_leaf_nodes = max_leaf_nodes, random_state = 0)\n    model.fit(X_train, y_train)\n    preds_val = model.predict(X_valid)\n    mae = mean_absolute_error(y_valid, preds_val)\n    return(mae)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T22:15:38.147498Z","iopub.execute_input":"2025-02-05T22:15:38.148390Z","iopub.status.idle":"2025-02-05T22:15:38.153841Z","shell.execute_reply.started":"2025-02-05T22:15:38.148339Z","shell.execute_reply":"2025-02-05T22:15:38.152620Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# For loop that prints MAE for a given list of nodes\nfor max_leaf_nodes in [5, 50, 500, 5000]:\n    mae = get_mae(max_leaf_nodes, X1_train, X1_valid, y1_train, y1_valid)\n    print(\"Max leaf nodes: %d  \\t\\t Mean Absolute Error:  %d\" %(max_leaf_nodes, mae))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T22:15:38.155423Z","iopub.execute_input":"2025-02-05T22:15:38.155856Z","iopub.status.idle":"2025-02-05T22:15:38.196954Z","shell.execute_reply.started":"2025-02-05T22:15:38.155819Z","shell.execute_reply":"2025-02-05T22:15:38.195946Z"}},"outputs":[{"name":"stdout","text":"Max leaf nodes: 5  \t\t Mean Absolute Error:  35044\nMax leaf nodes: 50  \t\t Mean Absolute Error:  27405\nMax leaf nodes: 500  \t\t Mean Absolute Error:  29454\nMax leaf nodes: 5000  \t\t Mean Absolute Error:  30162\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"# Trying Random Forest Regressor","metadata":{}},{"cell_type":"code","source":"# Define Random Forest Regressor Model\nrf_model = RandomForestRegressor(random_state=1)\n\n# Fit the model\nrf_model.fit(X1_train, y1_train)\n\n# Get predictions\nrf_predictions = rf_model.predict(X1_valid)\n\n# Print MAE\nrf_val_mae = mean_absolute_error(rf_predictions, y1_valid)\nprint(\"Validation MAE for Random Forest Model: \", rf_val_mae)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T22:15:38.198197Z","iopub.execute_input":"2025-02-05T22:15:38.198536Z","iopub.status.idle":"2025-02-05T22:15:38.694433Z","shell.execute_reply.started":"2025-02-05T22:15:38.198502Z","shell.execute_reply":"2025-02-05T22:15:38.693214Z"}},"outputs":[{"name":"stdout","text":"Validation MAE for Random Forest Model:  21857.15912981083\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"# Adding More Features to Random Forest Model","metadata":{}},{"cell_type":"code","source":"# List of columns that do not have missing values and are numerical\nfeatures2 = features + ['MSSubClass','LotArea','OverallQual','OverallCond','YearBuilt','YearRemodAdd','1stFlrSF','2ndFlrSF','LowQualFinSF','GrLivArea','FullBath',\n'HalfBath','BedroomAbvGr','KitchenAbvGr','TotRmsAbvGrd','Fireplaces','WoodDeckSF','OpenPorchSF','EnclosedPorch','3SsnPorch','ScreenPorch','PoolArea','MiscVal','MoSold','YrSold']\n\n# Select data and display it\nX2 = home_data[features2]\ndisplay(X2.head())\n\n# Split data into validation and training sets\nX2_train, X2_valid, y2_train, y2_valid = train_test_split(X2, y, random_state = 1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T22:15:38.696100Z","iopub.execute_input":"2025-02-05T22:15:38.696496Z","iopub.status.idle":"2025-02-05T22:15:38.722112Z","shell.execute_reply.started":"2025-02-05T22:15:38.696462Z","shell.execute_reply":"2025-02-05T22:15:38.721144Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"   LotArea  YearBuilt  1stFlrSF  2ndFlrSF  FullBath  BedroomAbvGr  \\\n0     8450       2003       856       854         2             3   \n1     9600       1976      1262         0         2             3   \n2    11250       2001       920       866         2             3   \n3     9550       1915       961       756         1             3   \n4    14260       2000      1145      1053         2             4   \n\n   TotRmsAbvGrd  MSSubClass  LotArea  OverallQual  ...  Fireplaces  \\\n0             8          60     8450            7  ...           0   \n1             6          20     9600            6  ...           1   \n2             6          60    11250            7  ...           1   \n3             7          70     9550            7  ...           1   \n4             9          60    14260            8  ...           1   \n\n   WoodDeckSF  OpenPorchSF  EnclosedPorch  3SsnPorch  ScreenPorch  PoolArea  \\\n0           0           61              0          0            0         0   \n1         298            0              0          0            0         0   \n2           0           42              0          0            0         0   \n3           0           35            272          0            0         0   \n4         192           84              0          0            0         0   \n\n   MiscVal  MoSold  YrSold  \n0        0       2    2008  \n1        0       5    2007  \n2        0       9    2008  \n3        0       2    2006  \n4        0      12    2008  \n\n[5 rows x 32 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>LotArea</th>\n      <th>YearBuilt</th>\n      <th>1stFlrSF</th>\n      <th>2ndFlrSF</th>\n      <th>FullBath</th>\n      <th>BedroomAbvGr</th>\n      <th>TotRmsAbvGrd</th>\n      <th>MSSubClass</th>\n      <th>LotArea</th>\n      <th>OverallQual</th>\n      <th>...</th>\n      <th>Fireplaces</th>\n      <th>WoodDeckSF</th>\n      <th>OpenPorchSF</th>\n      <th>EnclosedPorch</th>\n      <th>3SsnPorch</th>\n      <th>ScreenPorch</th>\n      <th>PoolArea</th>\n      <th>MiscVal</th>\n      <th>MoSold</th>\n      <th>YrSold</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>8450</td>\n      <td>2003</td>\n      <td>856</td>\n      <td>854</td>\n      <td>2</td>\n      <td>3</td>\n      <td>8</td>\n      <td>60</td>\n      <td>8450</td>\n      <td>7</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>61</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2008</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>9600</td>\n      <td>1976</td>\n      <td>1262</td>\n      <td>0</td>\n      <td>2</td>\n      <td>3</td>\n      <td>6</td>\n      <td>20</td>\n      <td>9600</td>\n      <td>6</td>\n      <td>...</td>\n      <td>1</td>\n      <td>298</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>2007</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>11250</td>\n      <td>2001</td>\n      <td>920</td>\n      <td>866</td>\n      <td>2</td>\n      <td>3</td>\n      <td>6</td>\n      <td>60</td>\n      <td>11250</td>\n      <td>7</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>42</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>9</td>\n      <td>2008</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9550</td>\n      <td>1915</td>\n      <td>961</td>\n      <td>756</td>\n      <td>1</td>\n      <td>3</td>\n      <td>7</td>\n      <td>70</td>\n      <td>9550</td>\n      <td>7</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>35</td>\n      <td>272</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2006</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>14260</td>\n      <td>2000</td>\n      <td>1145</td>\n      <td>1053</td>\n      <td>2</td>\n      <td>4</td>\n      <td>9</td>\n      <td>60</td>\n      <td>14260</td>\n      <td>8</td>\n      <td>...</td>\n      <td>1</td>\n      <td>192</td>\n      <td>84</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>12</td>\n      <td>2008</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 32 columns</p>\n</div>"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"# Define Random Forest Regressor\nrf_model_2 = RandomForestRegressor(random_state=1)\n\n# Fit the training data\nrf_model_2.fit(X2_train, y2_train)\n\n# Get predictions\nrf_predictions_2 = rf_model_2.predict(X2_valid)\n\n# Calculate and print MAE\nrf_val_mae_2 = mean_absolute_error(rf_predictions_2, y2_valid)\nprint(\"Validation MAE for Random Forest Model: \", rf_val_mae_2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T22:15:38.723619Z","iopub.execute_input":"2025-02-05T22:15:38.723975Z","iopub.status.idle":"2025-02-05T22:15:39.896435Z","shell.execute_reply.started":"2025-02-05T22:15:38.723927Z","shell.execute_reply":"2025-02-05T22:15:39.895246Z"}},"outputs":[{"name":"stdout","text":"Validation MAE for Random Forest Model:  17879.090684931507\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"# Trying Every Numerical Column","metadata":{}},{"cell_type":"markdown","source":"Getting Only Numerical Columns","metadata":{}},{"cell_type":"code","source":"# Selecting only numerical columns and displaying it\nX3 = X_full.select_dtypes(exclude=['object'])\ndisplay(X3.head())\n\n# Split data into training and validation data\nX3_train, X3_valid, y3_train, y3_valid = train_test_split(X3, y, train_size=.8, test_size=.2, random_state = 0)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T22:15:39.897779Z","iopub.execute_input":"2025-02-05T22:15:39.898267Z","iopub.status.idle":"2025-02-05T22:15:39.924823Z","shell.execute_reply.started":"2025-02-05T22:15:39.898225Z","shell.execute_reply":"2025-02-05T22:15:39.923601Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"   Id  MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n0   1          60         65.0     8450            7            5       2003   \n1   2          20         80.0     9600            6            8       1976   \n2   3          60         68.0    11250            7            5       2001   \n3   4          70         60.0     9550            7            5       1915   \n4   5          60         84.0    14260            8            5       2000   \n\n   YearRemodAdd  MasVnrArea  BsmtFinSF1  ...  GarageArea  WoodDeckSF  \\\n0          2003       196.0         706  ...         548           0   \n1          1976         0.0         978  ...         460         298   \n2          2002       162.0         486  ...         608           0   \n3          1970         0.0         216  ...         642           0   \n4          2000       350.0         655  ...         836         192   \n\n   OpenPorchSF  EnclosedPorch  3SsnPorch  ScreenPorch  PoolArea  MiscVal  \\\n0           61              0          0            0         0        0   \n1            0              0          0            0         0        0   \n2           42              0          0            0         0        0   \n3           35            272          0            0         0        0   \n4           84              0          0            0         0        0   \n\n   MoSold  YrSold  \n0       2    2008  \n1       5    2007  \n2       9    2008  \n3       2    2006  \n4      12    2008  \n\n[5 rows x 37 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>MSSubClass</th>\n      <th>LotFrontage</th>\n      <th>LotArea</th>\n      <th>OverallQual</th>\n      <th>OverallCond</th>\n      <th>YearBuilt</th>\n      <th>YearRemodAdd</th>\n      <th>MasVnrArea</th>\n      <th>BsmtFinSF1</th>\n      <th>...</th>\n      <th>GarageArea</th>\n      <th>WoodDeckSF</th>\n      <th>OpenPorchSF</th>\n      <th>EnclosedPorch</th>\n      <th>3SsnPorch</th>\n      <th>ScreenPorch</th>\n      <th>PoolArea</th>\n      <th>MiscVal</th>\n      <th>MoSold</th>\n      <th>YrSold</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>60</td>\n      <td>65.0</td>\n      <td>8450</td>\n      <td>7</td>\n      <td>5</td>\n      <td>2003</td>\n      <td>2003</td>\n      <td>196.0</td>\n      <td>706</td>\n      <td>...</td>\n      <td>548</td>\n      <td>0</td>\n      <td>61</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2008</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>20</td>\n      <td>80.0</td>\n      <td>9600</td>\n      <td>6</td>\n      <td>8</td>\n      <td>1976</td>\n      <td>1976</td>\n      <td>0.0</td>\n      <td>978</td>\n      <td>...</td>\n      <td>460</td>\n      <td>298</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>2007</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>60</td>\n      <td>68.0</td>\n      <td>11250</td>\n      <td>7</td>\n      <td>5</td>\n      <td>2001</td>\n      <td>2002</td>\n      <td>162.0</td>\n      <td>486</td>\n      <td>...</td>\n      <td>608</td>\n      <td>0</td>\n      <td>42</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>9</td>\n      <td>2008</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>70</td>\n      <td>60.0</td>\n      <td>9550</td>\n      <td>7</td>\n      <td>5</td>\n      <td>1915</td>\n      <td>1970</td>\n      <td>0.0</td>\n      <td>216</td>\n      <td>...</td>\n      <td>642</td>\n      <td>0</td>\n      <td>35</td>\n      <td>272</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2006</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>60</td>\n      <td>84.0</td>\n      <td>14260</td>\n      <td>8</td>\n      <td>5</td>\n      <td>2000</td>\n      <td>2000</td>\n      <td>350.0</td>\n      <td>655</td>\n      <td>...</td>\n      <td>836</td>\n      <td>192</td>\n      <td>84</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>12</td>\n      <td>2008</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 37 columns</p>\n</div>"},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"Creating a scoring function","metadata":{}},{"cell_type":"code","source":"# Function that will output the MAE when giving validation and training data\ndef score_dataset(X_train, X_valid, y_train, y_valid):\n    model = RandomForestRegressor(n_estimators=100, random_state=0)\n    model.fit(X_train, y_train)\n    preds = model.predict(X_valid)\n    return mean_absolute_error(y_valid, preds)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T22:15:39.926510Z","iopub.execute_input":"2025-02-05T22:15:39.926971Z","iopub.status.idle":"2025-02-05T22:15:39.934668Z","shell.execute_reply.started":"2025-02-05T22:15:39.926931Z","shell.execute_reply":"2025-02-05T22:15:39.933502Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"Dropping Columns with Missing Values","metadata":{}},{"cell_type":"code","source":"# List of numerical columns missing data\ncols_with_missing = [col for col in X3.columns \n                    if X3[col].isnull().any()]\n\n# Selecting all numerical columns without any missing data\nreduced_X3_train = X3_train.drop(cols_with_missing, axis=1)\nreduced_X3_valid = X3_valid.drop(cols_with_missing, axis=1)\n\n# Scoring dataset\nprint(\"MAE: \", score_dataset(reduced_X3_train, reduced_X3_valid, y3_train, y3_valid))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T22:15:39.936004Z","iopub.execute_input":"2025-02-05T22:15:39.936460Z","iopub.status.idle":"2025-02-05T22:15:41.283636Z","shell.execute_reply.started":"2025-02-05T22:15:39.936406Z","shell.execute_reply":"2025-02-05T22:15:41.282630Z"}},"outputs":[{"name":"stdout","text":"MAE:  17952.591404109586\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"Trying Imputation","metadata":{}},{"cell_type":"code","source":"# Defining Imputer\nmy_imputer = SimpleImputer(strategy = 'median')\n\n# Imputing Data\nimputed_X3_train = pd.DataFrame(my_imputer.fit_transform(X3_train))\nimputed_X3_valid = pd.DataFrame(my_imputer.transform(X3_valid)) \n\n\n# Imputation removed the column names so putting them back\nimputed_X3_train.columns = X3_train.columns\nimputed_X3_valid.columns = X3_valid.columns\n\n# Scoring dataset\nprint(\"MAE: \", score_dataset(imputed_X3_train, imputed_X3_valid, y3_train, y3_valid))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T22:15:41.285082Z","iopub.execute_input":"2025-02-05T22:15:41.285492Z","iopub.status.idle":"2025-02-05T22:15:42.820571Z","shell.execute_reply.started":"2025-02-05T22:15:41.285450Z","shell.execute_reply":"2025-02-05T22:15:42.819215Z"}},"outputs":[{"name":"stdout","text":"MAE:  18103.602945205483\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"# Using Categorical Variables","metadata":{}},{"cell_type":"markdown","source":"Oridinal Encoding","metadata":{}},{"cell_type":"code","source":"# Selecting and printing columns with missing values\ncols_with_missing = [col for col in X_full.columns if X_full[col].isnull().any()]\nprint(cols_with_missing)\n\n# Dropping columns with missing values\nX4 = X_full.copy().drop(cols_with_missing, axis=1)\n\n# Splitting validation and training data\nX4_train, X4_valid, y4_train, y4_valid = train_test_split(X4, y, train_size=0.8, test_size=0.2, random_state=0)\n\n# Categorical columns\nobject_cols = [col for col in X4_train.columns if X4_train[col].dtype == 'object']\n\n# Columns that can be safely ordinal encoded\ngood_label_cols = [col for col in object_cols if\n                  set(X4_valid[col]).issubset(set(X4_train[col]))]\n\n# Problematic columns \nbad_label_cols = list(set(object_cols)-set(good_label_cols))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T22:15:42.825871Z","iopub.execute_input":"2025-02-05T22:15:42.826368Z","iopub.status.idle":"2025-02-05T22:15:42.868371Z","shell.execute_reply.started":"2025-02-05T22:15:42.826298Z","shell.execute_reply":"2025-02-05T22:15:42.866804Z"}},"outputs":[{"name":"stdout","text":"['LotFrontage', 'Alley', 'MasVnrType', 'MasVnrArea', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Electrical', 'FireplaceQu', 'GarageType', 'GarageYrBlt', 'GarageFinish', 'GarageQual', 'GarageCond', 'PoolQC', 'Fence', 'MiscFeature']\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# Dropping problematic Columns\nlabel_X4_train = X4_train.drop(bad_label_cols, axis=1)\nlabel_X4_valid = X4_valid.drop(bad_label_cols, axis=1)\n\n# Defining Ordinal Encoder\nordinal_encoder = OrdinalEncoder()\n\n# Applying Ordinal Encoder to categorical data that is not problematic\nlabel_X4_train[good_label_cols] = ordinal_encoder.fit_transform(X4_train[good_label_cols])\nlabel_X4_valid[good_label_cols] = ordinal_encoder.transform(X4_valid[good_label_cols])\n\n# Scoring dataset\nprint('MAE: ', score_dataset(label_X4_train, label_X4_valid, y4_train, y4_valid))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T22:15:42.870215Z","iopub.execute_input":"2025-02-05T22:15:42.870713Z","iopub.status.idle":"2025-02-05T22:15:44.555291Z","shell.execute_reply.started":"2025-02-05T22:15:42.870670Z","shell.execute_reply":"2025-02-05T22:15:44.554155Z"}},"outputs":[{"name":"stdout","text":"MAE:  17251.037739726027\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"Trying a One-Hot-Encoder","metadata":{}},{"cell_type":"code","source":"# Finding low and high cardinality colmns.\n# Low cardinality columns were arbitrarilty chosen to have less than ten values \nlow_cardinality_cols = [col for col in object_cols if X4_train[col].nunique()<10]\nhigh_cardinality_cols = list(set(object_cols)-set(low_cardinality_cols))\nprint (high_cardinality_cols)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T22:15:44.556700Z","iopub.execute_input":"2025-02-05T22:15:44.557052Z","iopub.status.idle":"2025-02-05T22:15:44.572034Z","shell.execute_reply.started":"2025-02-05T22:15:44.557018Z","shell.execute_reply":"2025-02-05T22:15:44.570826Z"}},"outputs":[{"name":"stdout","text":"['Neighborhood', 'Exterior1st', 'Exterior2nd']\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# Defining One Hot Encoder\nOH_encoder = OneHotEncoder(handle_unknown='ignore', sparse = False)\n\n# Applying Encoder to each column with low cardinality\nOH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X4_train[low_cardinality_cols]))\nOH_cols_valid = pd.DataFrame(OH_encoder.transform(X4_valid[low_cardinality_cols]))\n\n# One-hot encoding removed index; put it back\nOH_cols_train.index = X4_train.index\nOH_cols_valid.index = X4_valid.index\n\n# Remove categorical columns\nnum_X4_train = X4_train.drop(object_cols, axis=1)\nnum_X4_valid = X4_valid.drop(object_cols, axis=1)\n\n# Add one-hot encoded columns to numerical features\nOH_X4_train = pd.concat([num_X4_train, OH_cols_train], axis=1)\nOH_X4_valid = pd.concat([num_X4_valid, OH_cols_valid], axis=1)\n\n# Ensure all columns have string Type\nOH_X4_train.columns = OH_X4_train.columns.astype(str)\nOH_X4_valid.columns = OH_X4_valid.columns.astype(str)\n\n# Score dataset\nprint(\"MAE: \", score_dataset(OH_X4_train, OH_X4_valid, y4_train, y4_valid))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T22:15:44.573291Z","iopub.execute_input":"2025-02-05T22:15:44.573712Z","iopub.status.idle":"2025-02-05T22:15:46.637756Z","shell.execute_reply.started":"2025-02-05T22:15:44.573654Z","shell.execute_reply":"2025-02-05T22:15:46.636632Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"MAE:  17514.224246575344\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"# Pipeline Implementation","metadata":{}},{"cell_type":"code","source":"# Select all predictor columns\nX5 = X_full.copy()\n\n# Split into validation and training data\nX5_train, X5_valid, y5_train, y5_valid = train_test_split(X5, y, train_size=0.8, test_size=0.2, random_state=0)\n\n# Categorical columns in the data\nall_object_cols_X5 = [col for col in X5.columns if X5[col].dtype == 'object']\n\n# Categorical columns that can be safely Ordinal Encoded\ncategorical_cols_X5 = [col for col in all_object_cols_X5 if\n                  set(X5_valid[col]).issubset(set(X5_train[col]))]\n\n# Selecting and displaying problematic categorical columns \nbad_label_cols_X5 = list(set(all_object_cols_X5)-set(categorical_cols_X5))\ndisplay(bad_label_cols_X5)\n\n# Dropping problematic columns\nX5_train.drop(bad_label_cols_X5, axis=1, inplace=True)\nX5_valid.drop(bad_label_cols_X5, axis=1, inplace=True) \n\n# Numerical Columns\nnumerical_cols_X5 = [col for col in X5.columns if \n                 X5[col].dtype in ['int64', 'float64']]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T22:15:46.639138Z","iopub.execute_input":"2025-02-05T22:15:46.639517Z","iopub.status.idle":"2025-02-05T22:15:46.667570Z","shell.execute_reply.started":"2025-02-05T22:15:46.639481Z","shell.execute_reply":"2025-02-05T22:15:46.666494Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"['MiscFeature', 'Condition2', 'RoofMatl', 'Functional']"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"# Preprocessing for numerical data\n# Simple Imputer will impute the average value to each missing variable\nnumerical_transformer = SimpleImputer(strategy='mean') \n\n# Preprocessing for categorical data\n# Simple Imputer will give a value to every missing variable\n# Ordinal Encoder will be able to handle unknown values found in the validation set, allowing for cross-validation later\ncategorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='constant')),\n                                         ('Ordinal encoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))]) \n\n# Bundle preprocessing for numerical and categorical data\npreprocessor = ColumnTransformer(transformers=[\n    ('num', numerical_transformer, numerical_cols_X5),\n    ('cat', categorical_transformer, categorical_cols_X5)\n])\n\n# Bundle preprocessing and a Random Forest Regressor model in a pipeline\npipeline_1 = Pipeline(steps=[('preprocessor', preprocessor),\n                             ('model', RandomForestRegressor(random_state=1))\n                             ])\n\n# Preprocessing of training data, fit model\npipeline_1.fit(X5_train, y5_train)\n\n# Get Predictions\npredictions = pipeline_1.predict(X5_valid)\n\n# Print MAE\nprint('MAE: ', mean_absolute_error(y5_valid, predictions))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T22:15:46.669099Z","iopub.execute_input":"2025-02-05T22:15:46.669571Z","iopub.status.idle":"2025-02-05T22:15:48.742981Z","shell.execute_reply.started":"2025-02-05T22:15:46.669523Z","shell.execute_reply":"2025-02-05T22:15:48.741669Z"}},"outputs":[{"name":"stdout","text":"MAE:  17087.34640410959\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"# Tweaking the Random Forest Regressor","metadata":{}},{"cell_type":"code","source":"# Function to return the average MAE over 3 CV folds of a Random Forest model for a given number of n_estimator\ndef get_score(n_estimators):\n    \n    # Create new pipeline with n_estimators as a variable\n    pipeline_2 = Pipeline(steps=[\n        ('preprocessor', preprocessor),\n        ('model', RandomForestRegressor(n_estimators=n_estimators, random_state=1))\n    ])\n    \n    # Get list of MAE using model \n    scores = -1 * cross_val_score(pipeline_2, X5, y,\n                                 cv = 3,\n                                 scoring = 'neg_mean_absolute_error') \n\n    # Return the average MAE\n    return scores.mean()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T22:15:48.744613Z","iopub.execute_input":"2025-02-05T22:15:48.745084Z","iopub.status.idle":"2025-02-05T22:15:48.752273Z","shell.execute_reply.started":"2025-02-05T22:15:48.745034Z","shell.execute_reply":"2025-02-05T22:15:48.750942Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\n\n# Create Dictionary\nresults = {}\n\n\n'''# For loop stores n_estimators in intervals of 50 from 50 - 400 and the MAE as keys and values respectively \nfor i in range(1,9):\n    results[i*50] = get_score(i*50)\n\n# Prints a graph plotting MAE vs. n_estimators in a Random Forest Regressor Model\nplt.plot(list(results.keys()), list(results.values()))\nplt.show()'''\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T22:15:48.753986Z","iopub.execute_input":"2025-02-05T22:15:48.754506Z","iopub.status.idle":"2025-02-05T22:15:48.770436Z","shell.execute_reply.started":"2025-02-05T22:15:48.754454Z","shell.execute_reply":"2025-02-05T22:15:48.769412Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"'# For loop stores n_estimators in intervals of 50 from 50 - 400 and the MAE as keys and values respectively \\nfor i in range(1,9):\\n    results[i*50] = get_score(i*50)\\n\\n# Prints a graph plotting MAE vs. n_estimators in a Random Forest Regressor Model\\nplt.plot(list(results.keys()), list(results.values()))\\nplt.show()'"},"metadata":{}}],"execution_count":21},{"cell_type":"markdown","source":"# Trying XGBoost","metadata":{}},{"cell_type":"code","source":"# Define the model \nXGB_model = XGBRegressor(n_estimators = 500, \n                           learning_rate=0.05,\n                        )\n\n# Create new pipeline with previous preprocessor and new model\npipeline_3 = Pipeline(steps=[\n                        ('preprocessor', preprocessor),\n                        ('model', XGB_model)\n])\n\n# Fit the model\npipeline_3.fit(X5_train, y5_train)\n\n# Get predictions\nXGB_preds = pipeline_3.predict(X5_valid)\n\n# Print MAE\nprint(\"MAE: \", mean_absolute_error(y5_valid, XGB_preds))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T22:15:48.771615Z","iopub.execute_input":"2025-02-05T22:15:48.772044Z","iopub.status.idle":"2025-02-05T22:15:53.759380Z","shell.execute_reply.started":"2025-02-05T22:15:48.771996Z","shell.execute_reply":"2025-02-05T22:15:53.758262Z"}},"outputs":[{"name":"stdout","text":"MAE:  17042.19630244007\n","output_type":"stream"}],"execution_count":22},{"cell_type":"markdown","source":"Adding hyperparamaters to XGBoost. Need to create another pipeline that will only preprocess the data, because pipeline_3 doesn't allow for early_stopping. Also note that pipeline_1 did not process all the categorical columns as X5_train dropped the bad columns. This new preprocessor will be able to process all columns. This is necessary for when we apply the entire data set to the model, we will be able to process every column without dropping necessary info. ","metadata":{}},{"cell_type":"code","source":"# Select all predictor columns\nX6 = X_full.copy()\n\n# Split into validation and training data\nX6_train, X6_valid, y6_train, y6_valid = train_test_split(X6, y, train_size = .8, test_size=.2, random_state = 0)\n\n# All categorical columns\ncategorical_cols_X6 = [col for col in X6.columns\n                if X6[col].dtype == 'object']\n\n# All numerical columns\nnumerical_cols_X6 = [col for col in X6.columns\n                if X6[col].dtype in ['int64', 'float64']]\n\n# Preprocessing for numerical columns\nnumerical_transformer_2 = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='mean'))\n])\n\n# Preprocessing for categorical columns\ncategorical_transformer_2 = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='constant')),\n    ('encoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n    #('onehot', OneHotEncoder(handle_unknown='ignore', sparse = False))\n])\n\n# Bundle preprocessing \npreprocessor_2 = ColumnTransformer(transformers=[\n    ('numerical_transformer', numerical_transformer_2, numerical_cols_X6),\n    ('categorical_transformer', categorical_transformer_2, categorical_cols_X6)\n])\n\n# Create pipeline for preprocessing\npreprocessing_pipeline = Pipeline(steps=[\n    ('preprocessor', preprocessor_2)\n])\n\n# Preprocess validation and training data\nX6_train_processed = preprocessing_pipeline.fit_transform(X6_train)\nX6_valid_processed = preprocessing_pipeline.transform(X6_valid)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T22:15:53.763716Z","iopub.execute_input":"2025-02-05T22:15:53.764175Z","iopub.status.idle":"2025-02-05T22:15:53.841555Z","shell.execute_reply.started":"2025-02-05T22:15:53.764126Z","shell.execute_reply":"2025-02-05T22:15:53.840216Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"# Define model\nXGB_model_2 = XGBRegressor(n_estimators = 500, \n                           learning_rate=0.05,\n                           )\n\n# Fit the model with early stopping rounds \nXGB_model_2.fit(X6_train_processed, y6_train,\n               early_stopping_rounds=20,\n               eval_set=[(X6_valid_processed, y6_valid)],\n               verbose=False)\n\n# Get predictions\nXGB_model_2_pred = XGB_model_2.predict(X6_valid_processed)\n\n# Print MAE\nprint(\"MAE: \", mean_absolute_error(y6_valid, XGB_model_2_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T22:15:53.843097Z","iopub.execute_input":"2025-02-05T22:15:53.843689Z","iopub.status.idle":"2025-02-05T22:15:59.574804Z","shell.execute_reply.started":"2025-02-05T22:15:53.843641Z","shell.execute_reply":"2025-02-05T22:15:59.573620Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"MAE:  16904.24075610017\n","output_type":"stream"}],"execution_count":24},{"cell_type":"markdown","source":"**Hypertuning Paramaters**","metadata":{}},{"cell_type":"code","source":"\"\"\"# Set paramater distributions\nparam_grid = {\n    'n_estimators': [100, 200, 500],\n    'learning_rate': [0.01, 0.05, 0.1],\n    'max_depth': [3, 6, 9],\n    'colsample_bytree': [0.5, 0.7, 1],\n    'subsample': [0.7, 0.8, 1],\n    'gamma': [0, 1, 5]\n}\n\n# Set up RandomizedSearchCV to find optimal paramaters\nsearch = RandomizedSearchCV(XGB_model_2, \n                            param_distributions=param_grid, \n                            cv=3, \n                            n_iter=50, \n                            scoring='neg_mean_absolute_error', \n                            random_state=0)\n\n# Fit the model\nsearch.fit(X6_train_processed, y6_train)\n\n# Print the results\nprint(\"Best parameters:\", search.best_params_)\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T22:15:59.577389Z","iopub.execute_input":"2025-02-05T22:15:59.577769Z","iopub.status.idle":"2025-02-05T22:15:59.593912Z","shell.execute_reply.started":"2025-02-05T22:15:59.577732Z","shell.execute_reply":"2025-02-05T22:15:59.592791Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"'# Set paramater distributions\\nparam_grid = {\\n    \\'n_estimators\\': [100, 200, 500],\\n    \\'learning_rate\\': [0.01, 0.05, 0.1],\\n    \\'max_depth\\': [3, 6, 9],\\n    \\'colsample_bytree\\': [0.5, 0.7, 1],\\n    \\'subsample\\': [0.7, 0.8, 1],\\n    \\'gamma\\': [0, 1, 5]\\n}\\n\\n# Set up RandomizedSearchCV to find optimal paramaters\\nsearch = RandomizedSearchCV(XGB_model_2, \\n                            param_distributions=param_grid, \\n                            cv=3, \\n                            n_iter=50, \\n                            scoring=\\'neg_mean_absolute_error\\', \\n                            random_state=0)\\n\\n# Fit the model\\nsearch.fit(X6_train_processed, y6_train)\\n\\n# Print the results\\nprint(\"Best parameters:\", search.best_params_)'"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"# XGBoost model with optimal paramaters\nXGB_model_3 = XGBRegressor(n_estimators = 500, \n                           learning_rate=0.05,\n                           max_depth=3,\n                           gamma=1,\n                           colsample_bytree=0.7,\n                           subsample=0.8)\n\n# Fit the model\n# Adding early stopping worsened scores\nXGB_model_3.fit(X6_train_processed, y6_train)\n\n# Get predictions\nXGB_model_3_pred = XGB_model_3.predict(X6_valid_processed)\n\n# Print MAE\nprint(\"MAE: \", mean_absolute_error(y6_valid, XGB_model_3_pred))\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T22:15:59.596012Z","iopub.execute_input":"2025-02-05T22:15:59.596487Z","iopub.status.idle":"2025-02-05T22:16:01.211893Z","shell.execute_reply.started":"2025-02-05T22:15:59.596439Z","shell.execute_reply":"2025-02-05T22:16:01.208521Z"}},"outputs":[{"name":"stdout","text":"MAE:  15586.202790560788\n","output_type":"stream"}],"execution_count":26},{"cell_type":"markdown","source":"# Final Submission","metadata":{}},{"cell_type":"code","source":"# Read test data\ntest_data_path = '/kaggle/input/home-data-for-ml-course/test.csv'\ntest_data = pd.read_csv(test_data_path)\n\n# Preprocess all the prediction data and fit the pipeline to its entirety\nprocessed_X6 = preprocessing_pipeline.fit_transform(X6)\n\n# Preprocess the testing data \nprocessed_test_data = preprocessing_pipeline.transform(test_data)\n\n# Final Model\nfinal_model = XGBRegressor(n_estimators = 500, \n                           learning_rate=0.05,\n                           max_depth=3,\n                           gamma=1,\n                           colsample_bytree=0.7,\n                           subsample=0.8)\n\n# Fit the model\nfinal_model.fit(processed_X6, y)\n\n# Get predictions from test data\ntest_preds = final_model.predict(processed_test_data)\n\n# Output Predictions\noutput = pd.DataFrame({'Id': test_data.Id,\n                       'SalePrice': test_preds})\noutput.to_csv('submission.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T22:16:01.213035Z","iopub.execute_input":"2025-02-05T22:16:01.216603Z","iopub.status.idle":"2025-02-05T22:16:01.907972Z","shell.execute_reply.started":"2025-02-05T22:16:01.216555Z","shell.execute_reply":"2025-02-05T22:16:01.906993Z"}},"outputs":[],"execution_count":27}]}